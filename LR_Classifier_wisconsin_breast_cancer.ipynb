{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries"
      ],
      "metadata": {
        "id": "LSaitjrG1pBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "byACNdvD10Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "VY3bv8Aeqe5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target"
      ],
      "metadata": {
        "id": "-y2LSc1ykUkb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring dataset"
      ],
      "metadata": {
        "id": "x0ABjMjMqZtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the names of the 13 features\n",
        "print(\"Features: \", cancer.feature_names)\n",
        "\n",
        "# print the label type of cancer('malignant' 'benign')\n",
        "print(\"Labels: \", cancer.target_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SMWyRqmlii7",
        "outputId": "61d4f43a-73f5-41bb-be25-fd259371233d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "Labels:  ['malignant' 'benign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print data(feature)shape\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuI03XrTl7ig",
        "outputId": "e22ea3f0-2333-4a0b-b8e4-1f386d7b78f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting Data\n",
        "To understand model performance, dividing the dataset into a training set and a test set is a good strategy.\n",
        "\n",
        "Split the dataset by using the function train_test_split(). we need to pass 3 parameters features, target, and test_set size.\n",
        "Additionally, we can use random_state to select records randomly.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDMb8W8ap_m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test\n"
      ],
      "metadata": {
        "id": "HRl7E-VvqEho"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling"
      ],
      "metadata": {
        "id": "ANNctNbRvqRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardize features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "eB5GPtkwv1sX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "kDgsbfZ-uxWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model without fixing the solver\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Perform K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=109)\n",
        "accuracy_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(f'Cross-validation accuracy scores: {accuracy_scores}')\n",
        "print(f'Mean cross-validation accuracy: {accuracy_scores.mean()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlBpK--CtsBo",
        "outputId": "ac8cc203-31be-49be-ac86-bf5f568b51d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracy scores: [0.9625     0.975      0.9875     0.93670886 0.98734177]\n",
            "Mean cross-validation accuracy: 0.9698101265822785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance of the Model"
      ],
      "metadata": {
        "id": "OTCCbEtMwWGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate on test data\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Test Accuracy: {accuracy}')\n",
        "print(f'Final Test Precision: {precision}')\n",
        "print(f'Final Test Recall: {recall}')\n",
        "print(f'Final Test F1-Score: {f1}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFcwMFVjvHV4",
        "outputId": "daaa8918-ce13-45ad-cf3c-a41e482500de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.9824561403508771\n",
            "Final Test Precision: 0.972972972972973\n",
            "Final Test Recall: 1.0\n",
            "Final Test F1-Score: 0.9863013698630136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning (GridSearchCV)"
      ],
      "metadata": {
        "id": "k9vFDJ--0No4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'solver': ['liblinear', 'lbfgs', 'saga'],  # Let GridSearchCV pick the best solver\n",
        "    'max_iter': [200, 500, 1000]\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(f'Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Best Cross-Validation Accuracy: {grid_search.best_score_}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yctct8zDxUQf",
        "outputId": "f4f4fa15-a255-48ad-e2fc-208004c79892"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.9647784810126583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on Test Dataset Using the Best Model"
      ],
      "metadata": {
        "id": "Vy6JkCRX0g2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on test dataset\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Test Accuracy: {accuracy}')\n",
        "print(f'Final Test Precision: {precision}')\n",
        "print(f'Final Test Recall: {recall}')\n",
        "print(f'Final Test F1-Score: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R16lGzGzeyn",
        "outputId": "ee6cd3be-218a-472b-8593-6e0ca915d70b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.9824561403508771\n",
            "Final Test Precision: 0.972972972972973\n",
            "Final Test Recall: 1.0\n",
            "Final Test F1-Score: 0.9863013698630136\n"
          ]
        }
      ]
    }
  ]
}